{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnaligase/PsychoPy_OdorBCI_shared/blob/main/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwBFsuAPtNL8",
        "outputId": "22fbc7fe-9312-47d4-ecba-90329fd4b7a5"
      },
      "source": [
        "#install mne, autoreject\n",
        "!pip install mne\n",
        "!pip install autoreject"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f7/2bf5de3fad42b66d00ee27539bc3be0260b4e66fdecc12f740cdf2daf2e7/mne-0.23.0-py3-none-any.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.23.0\n",
            "Collecting autoreject\n",
            "  Downloading https://files.pythonhosted.org/packages/00/00/1d93f88be662a1a65cae78261aad6856740a173c6947d47deaf91d70c47c/autoreject-0.2.2-py3-none-any.whl\n",
            "Installing collected packages: autoreject\n",
            "Successfully installed autoreject-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA5xQO3ArSIE",
        "outputId": "57da67fe-c920-4afe-c993-4945741c6bb1"
      },
      "source": [
        "#install libraries for our code\n",
        "import os, mne, glob, time\n",
        "import pandas as pd\n",
        "import numpy  as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import warnings\n",
        "\n",
        "from tqdm import tqdm\n",
        "from scipy import signal, special\n",
        "from autoreject import AutoReject\n",
        "from itertools import combinations\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "from google.colab import drive\n",
        "print('Libraries have been imported.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Libraries have been imported\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_tKd4JqMOZn",
        "outputId": "44c35e1a-78eb-4d23-c9fc-9851fb868c35"
      },
      "source": [
        "# open Google Drive via the link. Sign in if neccessary. Copy and paste the key to cell below to grat access Google Drive folders\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL_F0rIJfc6B",
        "outputId": "4c2cd97a-af55-4144-e8d0-aebadd7d02bb"
      },
      "source": [
        "# First add a shortcut to your drive. Open shared folder \"EEG_sliced\". http://bit.ly/EEG_sliced\n",
        "# Click an arrow right to the foldername. From the dropdown menu choose \"Add a shortcut to Drive\".\n",
        "# Shared folder \"EEG_sliced\" with the EEG data will appear in your Google Drive folder\n",
        "folder_path=\"/content/gdrive/MyDrive/Aspir/Olfactory-Dataset/New_data\"\n",
        "output_folder=\"/content/gdrive/MyDrive/EEG_sliced\"\n",
        "print('Folders has been set.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folders has been set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5IeO7I6fegA",
        "outputId": "d78001fc-551f-487f-bf54-f188ab348b91"
      },
      "source": [
        "#set the code of the participant. Leave blank(\"\") in order to use all files which name contain \"filt\"\n",
        "code=\"\"\n",
        "\n",
        "#let the code set the filename\n",
        "if code!='':\n",
        "  filename=code+'*filt*.fif'\n",
        "else:\n",
        "  filename='*filt*.fif'\n",
        "print(f'Code will look for {filename} file(s).')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Code will look for *filt*.fif file(s).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N_iFK65IUC_"
      },
      "source": [
        "# Function Space\n",
        "You will find the functions to work through the pipeline under the hood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkkUk5HYrSII",
        "outputId": "b3d84873-3288-46e2-dea0-608b7892abe7"
      },
      "source": [
        "def prepare_epochs(folder_path=str, tmin=0., tmax=2., l_freq=None, h_freq=20.,\n",
        "                   onset = 'inhale', exclude=[], save=False, filename=\"*ilt*.fif\", output_folder=\"/content/gdrive/MyDrive/EEG_sliced\"):\n",
        "  # CAN BE USED: exclude=[\"Fz\", \"Fp1\", \"Fp2\", \"P4\", \"T4\", \"T5\", \"T3\", \"T6\"]\n",
        "  \n",
        "  \"\"\"\n",
        "  Takes path to folder with .fif files as input. Outputs the list of tuples,\n",
        "  where each tuple contains the (1) EEG epochs per odor, (2) odor name,\n",
        "  (3) corresponding label, (4) subject id, (5) total number of epochs per odor.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "    folder_path : str\n",
        "        Folder with EEG files, by default str\n",
        "    tmin : float, optional\n",
        "         Starting point for the epoch, by default 0.0\n",
        "    tmax : float, optional\n",
        "        Endpoint for the epoch, by default 2.0\n",
        "    l_freq : list, optional\n",
        "        Low frequency filter, by default None\n",
        "    h_freq : float, optional\n",
        "        High frequency filter, by default 20.0\n",
        "    onset : str, optional\n",
        "        Epoch onset settings button/inhale, by default \"inhale\"\n",
        "    exclude : list, optional\n",
        "        Channels to be excluded, by default []\n",
        "    save : bool\n",
        "        Save epochs into new file, by default False\n",
        "    filename : str\n",
        "        Name of the file(s) to be sliced, by default \"*Filtered*.fif\"\n",
        "    output_folder: str\n",
        "        Path to the output folder. By deafult \"/content/gdrive/MyDrive/EEG_Sliced\"\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  epochs_sliced : list\n",
        "    List of tuples. See the docstring.\n",
        "  ch_names : list\n",
        "    List of channel names.\n",
        "  \"\"\"\n",
        "\n",
        "  # create an AutoReject object\n",
        "  ar = AutoReject(verbose=False)\n",
        "\n",
        "  # create epochs data\n",
        "  epochs_sliced = []\n",
        "\n",
        "  rel_path = os.path.abspath(\"\")\n",
        "\n",
        "  # Load list of raw EEG filenames\n",
        "  fnames = glob.glob(os.path.join(rel_path, folder_path, filename))\n",
        "\n",
        "  print(f\"Searching for {filename}\")\n",
        "  print(f\"\\nWORKING: Preparing {len(fnames)} filtered EEG raw file(s). This may take a while.\")\n",
        "\n",
        "  for fname in fnames:\n",
        "      print(f\"WORKING: Slicing {os.path.basename(fname)}\\n\")\n",
        "      raw = mne.io.read_raw_fif(fname, preload=True, verbose=False).pick(picks=None, exclude=exclude)\n",
        "      raw.filter(l_freq=l_freq, h_freq=h_freq, verbose=False)\n",
        "\n",
        "      # re-reference to 'common average'\n",
        "      mne.set_eeg_reference(raw, ref_channels='average', verbose=False)\n",
        "\n",
        "      # set onset inhale or button\n",
        "      if onset == 'inhale':\n",
        "        onset_regexp='^(?![Ii]|[Nn][Aa]|[Cc][Oo][Ff][Ff]|[Vv][Aa][Nn][Ii]|[Cc][Ii][Tt][Rr]|[Ww][Aa][Tt][Ee]|[Bb][Aa][Dd]|[Ee][Dd][Gg][Ee]).*$'\n",
        "        output_name=os.path.basename(fname)[:9]+\"_inhale-epo.fif\"\n",
        "      elif onset == 'button':\n",
        "        onset_regexp='^(?![Ii]|[Nn][Aa]|[Cc][Oo][Ff][_]|[Vv][Aa][Nn][_]|[Cc][Ii][Tt][_]|[Ww][Aa][Tt][_]|[Bb][Aa][Dd]|[Ee][Dd][Gg][Ee]).*$'\n",
        "        output_name=os.path.basename(fname)[:9]+\"_button-epo.fif\"\n",
        "      else:\n",
        "        # set button as default, print warning\n",
        "        onset_regexp='^(?![Ii]|[Nn][Aa]|[Cc][Oo][Ff][Ff]|[Vv][Aa][Nn][Ii]|[Cc][Ii][Tt][Rr]|[Ww][Aa][Tt][Ee]|[Bb][Aa][Dd]|[Ee][Dd][Gg][Ee]).*$'\n",
        "        output_name=os.path.basename(fname)[:9]+\"_button-epo.fif\"\n",
        "        warnings.warn(f'\\n Could not recognize {onset}. Consider \"inhale\" or \"button\" next time.\\nSetting to \"inhale\".', RuntimeWarning)\n",
        "\n",
        "      # extract inhalation events\n",
        "      events, event_id = mne.events_from_annotations(raw, regexp=onset_regexp)\n",
        "      print('\\n\\n {} events found.'.format(len(events)))\n",
        "\n",
        "      # slicing epochs\n",
        "      print(\"\\nWORKING: Slicing epochs with {} as an onset.  Time interval: {} - {}. Frequencies: {} - {}\".format(onset, tmin, tmax, l_freq, h_freq))\n",
        "      epochs_mne = mne.Epochs(raw, events, event_id, tmin=tmin, tmax=tmax, baseline=None, verbose=False)\n",
        "\n",
        "      # clean the epochs using AAR algorithm\n",
        "      epochs_clean = ar.fit_transform(epochs_mne.load_data())\n",
        "\n",
        "      for odor, idx in event_id.items():\n",
        "          epochs, labels = epochs_clean[odor].get_data(), epochs_clean[odor].events[:, -1]\n",
        "          \n",
        "          # create a list of tuples; normalize each trial by its std\n",
        "          trial = epochs / np.expand_dims(np.std(epochs, axis=-1), axis=-1), \\\n",
        "              odor, labels - 1, os.path.basename(fname)[:9], (events[:, 2] == idx).sum()\n",
        "\n",
        "          epochs_sliced.append(trial)\n",
        "\n",
        "      if save:\n",
        "        epochs_clean.save(os.path.join(output_folder,output_name))\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "  print('\\n ------DONE-----')\n",
        "\n",
        "  return epochs_sliced, epochs_clean.ch_names\n",
        "\n",
        "\n",
        "# define auxillary functions\n",
        "def average(a: list):\n",
        "    return sum(a) / len(a)\n",
        "\n",
        "def feats_reorder(ch_no=int):\n",
        "  \"\"\"\n",
        "  Reorder consecutive elements, e. g. [1, 2, 3, 4] -> [1, 3, 2, 4], if there\n",
        "  are n channels and 2 features per channel.\n",
        "  \"\"\"\n",
        "  idxs = np.arange(ch_no * 2)\n",
        "  idxs_reordered = np.insert(idxs[ch_no:], np.arange(len(idxs[:ch_no])), idxs[:ch_no])\n",
        "\n",
        "  return idxs_reordered \n",
        "\n",
        "print('All functions are successfully defined.')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All functions are successfully defined.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJJov-tZIPuF"
      },
      "source": [
        "# KNN\n",
        "KNN implementation based on two features (StDev and Average of Wavelet coefficients) per channel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEQ_jA_VHfwA",
        "outputId": "3f27f3bd-dd86-4b6c-a10c-cc8638045dc7"
      },
      "source": [
        "# crate epochs and channel names. get data, suitable for our problem\n",
        "epochs_sliced, ch_names = prepare_epochs(folder_path=folder_path, onset='button',tmin=-5, tmax=0., save=False, filename=filename, h_freq=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f13a00fa2628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# crate epochs and channel names. get data, suitable for our problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mepochs_sliced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'button'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'prepare_epochs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q75xYR8ZrSIJ",
        "scrolled": true,
        "outputId": "9f49d3b6-6dc9-476c-af70-1dd572f31c67"
      },
      "source": [
        "# how many classes we have\n",
        "odors_no = 4\n",
        "\n",
        "# total number of subjects used\n",
        "subjects_no = len(epochs_sliced) // odors_no\n",
        "# create list of odor pair tuples\n",
        "combs = list(combinations([i for i in range(odors_no)], r=2))\n",
        "\n",
        "# k-NN classifier\n",
        "accuracies = np.zeros((subjects_no, special.comb(4, 2, exact=True)))\n",
        "neigh = KNeighborsClassifier(n_neighbors=13)\n",
        "d = {\"subj_id\": [], \"age\": [], \"sex\": [], \"odor_1_categ\": [], \"odor_2_categ\": [], \"odor_1\": [], \"odor_2\": [], \"best_acc\": [], \"best_chan\": []}\n",
        "\n",
        "# first, select a subject\n",
        "for subject_id in tqdm(range(subjects_no)):\n",
        "    pairwise_scores = []\n",
        "    # second, select an odor pair\n",
        "    for j, k in tqdm(combs):\n",
        "\n",
        "        epochs_paired = np.concatenate([epochs_sliced[subject_id * odors_no + j][0], \\\n",
        "            epochs_sliced[subject_id * odors_no + k][0]])\n",
        "\n",
        "        labels_paired = np.concatenate([epochs_sliced[subject_id * odors_no + j][2], \\\n",
        "            epochs_sliced[subject_id * odors_no + k][2]])\n",
        "\n",
        "        # here we calculate wavelet-transform coefficients (WTC) in the alpha-band 8-13 Hz\n",
        "        coefs = signal.cwt(epochs_paired[:, :, :].flatten(), signal.morlet2, np.arange(8, 13))\n",
        "\n",
        "        # as the output is imaginary, let's find an absolute values\n",
        "        # also averaging CWT in a band\n",
        "        coefs_band = abs(coefs.mean(axis=0))\n",
        "\n",
        "        # returning initial shape of an array\n",
        "        coefs_band = coefs_band.reshape(epochs_paired.shape[0], epochs_paired.shape[1], -1)\n",
        "        # finding average and st. dev. of WTC\n",
        "        A_wtc, S_wtc = coefs_band.mean(axis=-1), np.std(coefs_band, axis=-1)\n",
        "        \n",
        "        # stack features so that for single trial they are:\n",
        "        # [A_wtc_ch1, A_wtc_ch2, A_wtc_ch3, S_wtc_ch1, S_wtc_ch2, S_wtc_ch3]\n",
        "        wtc_final = np.hstack((A_wtc, S_wtc))\n",
        "\n",
        "        # reoder features, e. g. [A_wtc_ch1, S_wtc_ch1, ...]\n",
        "        idxs = feats_reorder(len(ch_names))\n",
        "        wtc_final_reorder = wtc_final[:, idxs]\n",
        "\n",
        "        ch_scores = []\n",
        "        per_chan_std = []\n",
        "        # third, for each individual and each odor pair calculate prediction accuracy for each channel\n",
        "        for ch in range(len(ch_names)):\n",
        "        \n",
        "            testscore = []\n",
        "            trainscore = []\n",
        "            \n",
        "            X = wtc_final_reorder[:, ch*2 : (ch + 1) * 2]\n",
        "            y = labels_paired\n",
        "            kf = RepeatedKFold(n_splits=5, n_repeats=20)\n",
        "            \n",
        "\n",
        "            for train_index, test_index in kf.split(X):\n",
        "                X_train, X_test = X[train_index], X[test_index]\n",
        "                y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "                neigh.fit(X_train, y_train)\n",
        "                testscore.append(neigh.score(X_test, y_test))\n",
        "                trainscore.append(neigh.score(X_train, y_train))\n",
        "\n",
        "            # per_chan_std.append(np.std(ch_scores))\n",
        "            ch_scores.append(np.round(average(testscore), decimals=3))\n",
        "        \n",
        "        # create dictionary of subject id, odor1, odor2, max accuracy across the chs, best ch name\n",
        "        d['subj_id'].append(epochs_sliced[subject_id * odors_no][3])\n",
        "        d['age'].append(epochs_sliced[subject_id * odors_no][3][-3:-1])\n",
        "        d['sex'].append(epochs_sliced[subject_id * odors_no][3][-1])\n",
        "        d['odor_1_categ'].append(epochs_sliced[j][1])\n",
        "        d['odor_2_categ'].append(epochs_sliced[k][1])\n",
        "        d['odor_1'].append(j)\n",
        "        d['odor_2'].append(k)\n",
        "        d['best_acc'].append(np.max(ch_scores))\n",
        "        # d['std'].append(per_chan_std[np.argmax(ch_scores)])\n",
        "        d['best_chan'].append(ch_names[np.argmax(ch_scores)])\n",
        "\n",
        "        pairwise_scores.append(np.max(ch_scores))\n",
        "\n",
        "    accuracies[subject_id, :] = pairwise_scores\n",
        "print(\"\\n---DONE---\")\n",
        "print(accuracies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:05<00:29,  5.86s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:14<00:26,  6.69s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:23<00:21,  7.33s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:28<00:13,  6.81s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:34<00:06,  6.49s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:40<00:00,  6.73s/it]\n",
            "\n",
            "  6%|▋         | 1/16 [00:40<10:06, 40.41s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:08<00:40,  8.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:16<00:32,  8.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:24<00:24,  8.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:33<00:16,  8.27s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:41<00:08,  8.33s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:50<00:00,  8.38s/it]\n",
            "\n",
            " 12%|█▎        | 2/16 [01:30<10:07, 43.37s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:10<00:50, 10.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:20<00:40, 10.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:30<00:30, 10.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:40<00:20, 10.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:50<00:10, 10.19s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [01:01<00:00, 10.18s/it]\n",
            "\n",
            " 19%|█▉        | 3/16 [02:31<10:32, 48.68s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:08<00:43,  8.77s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:17<00:34,  8.69s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:26<00:26,  8.72s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:34<00:17,  8.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:42<00:08,  8.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:50<00:00,  8.49s/it]\n",
            "\n",
            " 25%|██▌       | 4/16 [03:22<09:52, 49.37s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:08<00:41,  8.34s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:17<00:34,  8.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:26<00:26,  8.79s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:35<00:17,  8.70s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:44<00:08,  8.78s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:53<00:00,  8.95s/it]\n",
            "\n",
            " 31%|███▏      | 5/16 [04:16<09:17, 50.68s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:10<00:51, 10.39s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:21<00:42, 10.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:31<00:31, 10.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:42<00:20, 10.50s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:52<00:10, 10.45s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [01:02<00:00, 10.47s/it]\n",
            "\n",
            " 38%|███▊      | 6/16 [05:19<09:03, 54.33s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:09<00:45,  9.02s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:18<00:36,  9.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:27<00:27,  9.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:36<00:18,  9.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:45<00:09,  9.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:54<00:00,  9.12s/it]\n",
            "\n",
            " 44%|████▍     | 7/16 [06:14<08:10, 54.45s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:10<00:50, 10.09s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:19<00:39,  9.92s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:29<00:29,  9.96s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:39<00:19,  9.86s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:49<00:09,  9.90s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:59<00:00,  9.84s/it]\n",
            "\n",
            " 50%|█████     | 8/16 [07:13<07:26, 55.84s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:10<00:51, 10.34s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:20<00:41, 10.37s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:31<00:31, 10.38s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:41<00:20, 10.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:52<00:10, 10.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [01:02<00:00, 10.48s/it]\n",
            "\n",
            " 56%|█████▋    | 9/16 [08:16<06:45, 57.95s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:09<00:48,  9.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:19<00:38,  9.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:28<00:28,  9.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:38<00:19,  9.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:48<00:09,  9.71s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:57<00:00,  9.64s/it]\n",
            "\n",
            " 62%|██████▎   | 10/16 [09:13<05:47, 57.92s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:09<00:47,  9.42s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:18<00:37,  9.29s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:27<00:27,  9.27s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:36<00:18,  9.05s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:45<00:09,  9.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:53<00:00,  8.93s/it]\n",
            "\n",
            " 69%|██████▉   | 11/16 [10:07<04:43, 56.62s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:09<00:48,  9.78s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:19<00:38,  9.74s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:29<00:29,  9.71s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:38<00:19,  9.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:47<00:09,  9.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:56<00:00,  9.44s/it]\n",
            "\n",
            " 75%|███████▌  | 12/16 [11:04<03:46, 56.64s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:09<00:45,  9.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:17<00:35,  9.00s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:26<00:26,  8.95s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:35<00:17,  8.93s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:44<00:08,  8.94s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:52<00:00,  8.83s/it]\n",
            "\n",
            " 81%|████████▏ | 13/16 [11:57<02:46, 55.54s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:09<00:48,  9.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:19<00:38,  9.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:28<00:28,  9.39s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:37<00:18,  9.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:47<00:09,  9.42s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [00:55<00:00,  9.33s/it]\n",
            "\n",
            " 88%|████████▊ | 14/16 [12:53<01:51, 55.67s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:10<00:50, 10.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:20<00:40, 10.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:30<00:30, 10.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:40<00:20, 10.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:50<00:10, 10.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [01:00<00:00, 10.13s/it]\n",
            "\n",
            " 94%|█████████▍| 15/16 [13:53<00:57, 57.21s/it]\u001b[A\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 1/6 [00:10<00:50, 10.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 2/6 [00:20<00:40, 10.06s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 3/6 [00:30<00:30, 10.06s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:40<00:20, 10.03s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 5/6 [00:50<00:10, 10.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 6/6 [01:00<00:00, 10.08s/it]\n",
            "\n",
            "100%|██████████| 16/16 [14:54<00:00, 55.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---DONE---\n",
            "[[0.6   0.518 0.516 0.387 0.547 0.495]\n",
            " [0.596 0.657 0.548 0.632 0.61  0.561]\n",
            " [0.6   0.669 0.735 0.705 0.677 0.688]\n",
            " [0.606 0.614 0.627 0.507 0.621 0.598]\n",
            " [0.577 0.574 0.618 0.612 0.64  0.608]\n",
            " [0.627 0.659 0.64  0.598 0.55  0.622]\n",
            " [0.603 0.58  0.679 0.605 0.582 0.608]\n",
            " [0.608 0.657 0.558 0.588 0.665 0.589]\n",
            " [0.576 0.565 0.556 0.645 0.625 0.605]\n",
            " [0.586 0.611 0.636 0.627 0.561 0.634]\n",
            " [0.578 0.563 0.561 0.536 0.643 0.654]\n",
            " [0.509 0.554 0.649 0.52  0.605 0.694]\n",
            " [0.627 0.692 0.609 0.668 0.617 0.68 ]\n",
            " [0.634 0.554 0.598 0.563 0.6   0.646]\n",
            " [0.593 0.617 0.773 0.599 0.62  0.726]\n",
            " [0.681 0.656 0.676 0.582 0.584 0.576]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "LLN-akzjOF6i",
        "outputId": "5a631de5-a229-4402-f228-a9acb7371640"
      },
      "source": [
        "table = pd.DataFrame(d)\n",
        "table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subj_id</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>odor_1_categ</th>\n",
              "      <th>odor_2_categ</th>\n",
              "      <th>odor_1</th>\n",
              "      <th>odor_2</th>\n",
              "      <th>best_acc</th>\n",
              "      <th>best_chan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1R912_39F</td>\n",
              "      <td>39</td>\n",
              "      <td>F</td>\n",
              "      <td>cit_inhale</td>\n",
              "      <td>cof_inhale</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.600</td>\n",
              "      <td>C4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1R912_39F</td>\n",
              "      <td>39</td>\n",
              "      <td>F</td>\n",
              "      <td>cit_inhale</td>\n",
              "      <td>van_inhale</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.518</td>\n",
              "      <td>P3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1R912_39F</td>\n",
              "      <td>39</td>\n",
              "      <td>F</td>\n",
              "      <td>cit_inhale</td>\n",
              "      <td>wat_inhale</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.516</td>\n",
              "      <td>T3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1R912_39F</td>\n",
              "      <td>39</td>\n",
              "      <td>F</td>\n",
              "      <td>cof_inhale</td>\n",
              "      <td>van_inhale</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.387</td>\n",
              "      <td>Cz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1R912_39F</td>\n",
              "      <td>39</td>\n",
              "      <td>F</td>\n",
              "      <td>cof_inhale</td>\n",
              "      <td>wat_inhale</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.547</td>\n",
              "      <td>O2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>ZU9B3_34M</td>\n",
              "      <td>34</td>\n",
              "      <td>M</td>\n",
              "      <td>cit_inhale</td>\n",
              "      <td>van_inhale</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.656</td>\n",
              "      <td>T4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>ZU9B3_34M</td>\n",
              "      <td>34</td>\n",
              "      <td>M</td>\n",
              "      <td>cit_inhale</td>\n",
              "      <td>wat_inhale</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.676</td>\n",
              "      <td>Fp2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>ZU9B3_34M</td>\n",
              "      <td>34</td>\n",
              "      <td>M</td>\n",
              "      <td>cof_inhale</td>\n",
              "      <td>van_inhale</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.582</td>\n",
              "      <td>T6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>ZU9B3_34M</td>\n",
              "      <td>34</td>\n",
              "      <td>M</td>\n",
              "      <td>cof_inhale</td>\n",
              "      <td>wat_inhale</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.584</td>\n",
              "      <td>T3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>ZU9B3_34M</td>\n",
              "      <td>34</td>\n",
              "      <td>M</td>\n",
              "      <td>van_inhale</td>\n",
              "      <td>wat_inhale</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.576</td>\n",
              "      <td>Fp2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      subj_id age sex odor_1_categ  ... odor_1  odor_2  best_acc  best_chan\n",
              "0   1R912_39F  39   F   cit_inhale  ...      0       1     0.600         C4\n",
              "1   1R912_39F  39   F   cit_inhale  ...      0       2     0.518         P3\n",
              "2   1R912_39F  39   F   cit_inhale  ...      0       3     0.516         T3\n",
              "3   1R912_39F  39   F   cof_inhale  ...      1       2     0.387         Cz\n",
              "4   1R912_39F  39   F   cof_inhale  ...      1       3     0.547         O2\n",
              "..        ...  ..  ..          ...  ...    ...     ...       ...        ...\n",
              "91  ZU9B3_34M  34   M   cit_inhale  ...      0       2     0.656         T4\n",
              "92  ZU9B3_34M  34   M   cit_inhale  ...      0       3     0.676        Fp2\n",
              "93  ZU9B3_34M  34   M   cof_inhale  ...      1       2     0.582         T6\n",
              "94  ZU9B3_34M  34   M   cof_inhale  ...      1       3     0.584         T3\n",
              "95  ZU9B3_34M  34   M   van_inhale  ...      2       3     0.576        Fp2\n",
              "\n",
              "[96 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0ynslF7pwe-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}